<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance · Luma.jl</title><meta name="title" content="Performance · Luma.jl"/><meta property="og:title" content="Performance · Luma.jl"/><meta property="twitter:title" content="Performance · Luma.jl"/><meta name="description" content="Documentation for Luma.jl."/><meta property="og:description" content="Documentation for Luma.jl."/><meta property="twitter:description" content="Documentation for Luma.jl."/><meta property="og:url" content="https://epilliat.github.io/Luma.jl/stable/performances/"/><meta property="twitter:url" content="https://epilliat.github.io/Luma.jl/stable/performances/"/><link rel="canonical" href="https://epilliat.github.io/Luma.jl/stable/performances/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Luma.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Performance</a><ul class="internal"><li><a class="tocitem" href="#Copy"><span>Copy</span></a></li><li><a class="tocitem" href="#Map-Reduce"><span>Map-Reduce</span></a></li><li><a class="tocitem" href="#Scan"><span>Scan</span></a></li><li><a class="tocitem" href="#Matrix-Vector-Operations"><span>Matrix-Vector Operations</span></a></li></ul></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Performance</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Performance</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/epilliat/Luma.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/epilliat/Luma.jl/blob/main/docs/src/performances.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Performance"><a class="docs-heading-anchor" href="#Performance">Performance</a><a id="Performance-1"></a><a class="docs-heading-anchor-permalink" href="#Performance" title="Permalink"></a></h1><p>Luma.jl achieves performance comparable to optimized CUDA C++ libraries such as CUB. Benchmarks report two metrics:</p><ul><li><strong>Kernel time</strong>: Execution time of the main kernel, measured using <code>@profile</code> from CUDA.jl</li><li><strong>Overhead</strong>: Total time minus kernel time, including memory allocations and data transfers</li></ul><h2 id="Copy"><a class="docs-heading-anchor" href="#Copy">Copy</a><a id="Copy-1"></a><a class="docs-heading-anchor-permalink" href="#Copy" title="Permalink"></a></h2><p>CUDA.jl leverages the proprietary libcuda library for memory copies, which internally vectorizes loads and stores. In contrast, the cross-platform GPUArrayCore.jl relies on KernelAbstractions.jl, which does not currently perform vectorization. Luma&#39;s <code>vcopy!</code> bridges this gap by using <code>vload</code> and <code>vstore</code> operations built on unsafe pointer access via LLVMPtrs from KernelIntrinsics.jl.</p><p>The graph below compares memory bandwidth for Float32 and UInt8 data types. With vectorized loads and stores, Luma achieves bandwidth comparable to CUDA.jl for both types. The slight underperformance below the L2 cache threshold stems from our current vectorization factor (×8 for Float32); increasing this to ×16 would close the remaining gap.</p><p><img src="../assets/copy_bandwidth.png" alt="Copy Bandwidth"/></p><h2 id="Map-Reduce"><a class="docs-heading-anchor" href="#Map-Reduce">Map-Reduce</a><a id="Map-Reduce-1"></a><a class="docs-heading-anchor-permalink" href="#Map-Reduce" title="Permalink"></a></h2><p>Luma.jl matches CUDA.jl performance on Float32 and significantly outperforms it on smaller types (UInt8, UnitFloat8), even when converting to Float32 during reduction. These gains result from optimized memory access patterns and vectorized loads/stores.</p><p><img src="../assets/mapreduce_benchmark_comparison.png" alt="Map-Reduce Benchmark"/></p><h2 id="Scan"><a class="docs-heading-anchor" href="#Scan">Scan</a><a id="Scan-1"></a><a class="docs-heading-anchor-permalink" href="#Scan" title="Permalink"></a></h2><p>Luma&#39;s scan kernel rivals CUB performance on Float32 and Float64, while additionally supporting non-commutative operations and custom types such as Quaternions. This is achieved through an efficient decoupled lookback algorithm combined with optimized memory access.</p><p><img src="../assets/scan_benchmark_comparison.png" alt="Scan Benchmark"/></p><h2 id="Matrix-Vector-Operations"><a class="docs-heading-anchor" href="#Matrix-Vector-Operations">Matrix-Vector Operations</a><a id="Matrix-Vector-Operations-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-Vector-Operations" title="Permalink"></a></h2><p>Luma implements matrix-vector and vector-matrix operations for general types and operators. For benchmarking, we compare against CUDA.jl on Float32, which internally calls cuBLAS&#39;s <code>gemv</code> routine.</p><p>Due to column-major memory layout, matrix-vector and vector-matrix multiplications have fundamentally different access patterns. Luma therefore provides separate optimized kernels for each operation.</p><p>For both benchmarks, we fix the total matrix size (n × p) and vary n from 10 to (n × p) / 10, sweeping from tall-narrow to short-wide matrices. The black line indicates the reduced overhead achieved when the user provides pre-allocated temporary memory.</p><p><strong>Matrix-Vector</strong> <img src="../assets/matvec_benchmark_comparison.png" alt="Matrix-Vector Benchmark"/></p><p><strong>Vector-Matrix</strong></p><p><img src="../assets/vecmat_benchmark_comparison.png" alt="Vector-Matrix Benchmark"/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../examples/">Examples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Tuesday 3 February 2026 12:49">Tuesday 3 February 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
